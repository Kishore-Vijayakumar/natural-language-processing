{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyTgM8skT7dP"
   },
   "source": [
    "## <u>Part One - PROJECT BASED </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dw6gfmAsT7dT"
   },
   "source": [
    "• <b>DOMAIN:</b>  Digital content management \n",
    "\n",
    "• <b>CONTEXT:</b> : Classification is probably the most popular task that you would deal with in real life. Text in the form of blogs, posts, articles,\n",
    "etc. is written every second. It is a challenge to predict the information about the writer without knowing about him/her. We are going to\n",
    "create a classifier that predicts multiple features of the author of a given text. We have designed it as a Multi label classification problem.\n",
    "\n",
    "• <b>DATA DESCRIPTION:</b> Over 600,000 posts from more than 19 thousand bloggers The Blog Authorship Corpus consists of the collected\n",
    "posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million\n",
    "words - or approximately 35 posts and 7250 words per person. Each blog is presented as a separate file, the name of which indicates a\n",
    "blogger id# and the blogger’s self-provided gender, age, industry, and astrological sign. (All are labelled for gender and age but for many,\n",
    "industry and/or sign is marked as unknown.) All bloggers included in the corpus fall into one of three age groups:<br>\n",
    "    • 8240 \"10s\" blogs (ages 13-17),<br>\n",
    "    • 8086 \"20s\" blogs(ages 23-27) and<br>\n",
    "    • 2994 \"30s\" blogs (ages 33-47)<br>\n",
    "For each age group, there is an equal number of male and female bloggers.\n",
    "Each blog in the corpus includes at least 200 occurrences of common English words. All formatting has been stripped with two exceptions.\n",
    "Individual posts within a single blogger are separated by the date of the following post and links within a post are denoted by the label url\n",
    "link. Link to dataset: https://www.kaggle.com/rtatman/blog-authorship-corpus<br>\n",
    "\n",
    "• <b>PROJECT OBJECTIVE:</b> : The need is to build a NLP classifier which can use input text parameters to determine the label/s of the blog.\n",
    "\n",
    "<b>Steps and tasks:  </b>\n",
    "\n",
    "1. Import and analyse the data set.\n",
    "2. Perform data pre-processing on the data:<br>\n",
    "    • Data cleansing by removing unwanted characters, spaces, stop words etc.Convert text to lowercase.<br>\n",
    "    • Target/label merger and transformation<br>\n",
    "    • Train and test split<br>\n",
    "    • Vectorisation, etc<br>\n",
    "3. Design, train, tune and test the best text classifier.<br>\n",
    "   \n",
    "4. Display and explain detail the classification report.<br>\n",
    "5. Print the true vs predicted labels for any 5 entries from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JN2BrEKgT7dz"
   },
   "source": [
    "### <u>Solution</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sgg7Rit04_-5",
    "outputId": "a1d58900-e4fa-4e6b-db83-7ce356492b71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-ZJEXUPI5AfJ",
    "outputId": "a4fcd222-d15b-4489-d663-77708ec33684"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9hDPzqoNqJf5",
    "outputId": "13be92d0-514c-46b1-be83-2f9858c2f9f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DIn9ZwURA0-"
   },
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nVpwWqFMri0W"
   },
   "outputs": [],
   "source": [
    "blog_data = pd.read_csv(\"/content/drive/MyDrive/AIML/Labs/CV/blogtext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "pn5ZJF-Trij4",
    "outputId": "cfae8951-bffc-4ce2-e04b-30fd24343444"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c90bffce-9f68-4dd3-8641-8f4a4f491895\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>I had an interesting conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>Somehow Coca-Cola has a way of su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>If anything, Korea is a country o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>10,June,2004</td>\n",
       "      <td>Take a read of this news article ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>09,June,2004</td>\n",
       "      <td>I surf the English news sites a l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c90bffce-9f68-4dd3-8641-8f4a4f491895')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c90bffce-9f68-4dd3-8641-8f4a4f491895 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c90bffce-9f68-4dd3-8641-8f4a4f491895');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "5  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "6  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "7  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "8  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
       "9  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  \n",
       "5               I had an interesting conversation...  \n",
       "6               Somehow Coca-Cola has a way of su...  \n",
       "7               If anything, Korea is a country o...  \n",
       "8               Take a read of this news article ...  \n",
       "9               I surf the English news sites a l...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_data.head(10) #Sample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jI4DAJXBrigg",
    "outputId": "ac9d1285-a688-4db6-db73-17d74ca480c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(681284, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZmVviPurido",
    "outputId": "a8f7f38e-7190-454f-a194-e7c2c3e84386"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4768988"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_data.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-I4ppTuaSYd0"
   },
   "source": [
    "Here we can see a huge data set of 681284 rows and 7 columns. It is difficult to process this big data, so we are taking only a sample of record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eAK_bpkrribE"
   },
   "outputs": [],
   "source": [
    "data1 = blog_data.head(10000).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDizTxZ1riYa",
    "outputId": "3a65093d-129b-4988-f0c3-0aee0c87b843"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dyACkTHEriVT",
    "outputId": "9c2b3e58-ef6c-4cc3-a193-b6735cd60e81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        False\n",
       "gender    False\n",
       "age       False\n",
       "topic     False\n",
       "sign      False\n",
       "date      False\n",
       "text      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBrP1iYcTPj-"
   },
   "source": [
    "No null values at present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e94aaEaoriSg",
    "outputId": "ee1ad025-bf9f-4a96-bbfd-f75000766ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      10000 non-null  int64 \n",
      " 1   gender  10000 non-null  object\n",
      " 2   age     10000 non-null  int64 \n",
      " 3   topic   10000 non-null  object\n",
      " 4   sign    10000 non-null  object\n",
      " 5   date    10000 non-null  object\n",
      " 6   text    10000 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 547.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "kPDPPj4griPy",
    "outputId": "0e9294df-2fe0-480f-d132-e2d650038b71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8459e592-53a2-4032-8523-e6705924e55c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>I had an interesting conversation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>Somehow Coca-Cola has a way of su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>If anything, Korea is a country o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>Take a read of this news article ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>I surf the English news sites a l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8459e592-53a2-4032-8523-e6705924e55c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8459e592-53a2-4032-8523-e6705924e55c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8459e592-53a2-4032-8523-e6705924e55c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  gender  age              topic      sign  \\\n",
       "0   male   15            Student       Leo   \n",
       "1   male   15            Student       Leo   \n",
       "2   male   15            Student       Leo   \n",
       "3   male   15            Student       Leo   \n",
       "4   male   33  InvestmentBanking  Aquarius   \n",
       "5   male   33  InvestmentBanking  Aquarius   \n",
       "6   male   33  InvestmentBanking  Aquarius   \n",
       "7   male   33  InvestmentBanking  Aquarius   \n",
       "8   male   33  InvestmentBanking  Aquarius   \n",
       "9   male   33  InvestmentBanking  Aquarius   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  \n",
       "5               I had an interesting conversation...  \n",
       "6               Somehow Coca-Cola has a way of su...  \n",
       "7               If anything, Korea is a country o...  \n",
       "8               Take a read of this news article ...  \n",
       "9               I surf the English news sites a l...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can drop columns \"id\" & \"date\" from the dataset since they dont convey any meaning to our problem\n",
    "data1.drop(['id','date'],axis=1,inplace=True)\n",
    "data1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dTg6579iriNA"
   },
   "outputs": [],
   "source": [
    "data1['age']=data1['age'].astype('object') #Converting int to object, taking age as a object category instead of int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJn0NUVTriKQ",
    "outputId": "0d8fc8c3-3876-4f7a-a16e-b9850d94bd73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   gender  10000 non-null  object\n",
      " 1   age     10000 non-null  object\n",
      " 2   topic   10000 non-null  object\n",
      " 3   sign    10000 non-null  object\n",
      " 4   text    10000 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data1.info() #Converted all columns to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "5xYKkvZAriEu",
    "outputId": "46fec437-cfb4-4961-861c-cf28c40083e6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"             As readers will know, my favorite airline is Singapore Air (SAI).  They have those personal monitors for everyone with on-demand movies, TV shows and games..and some lovely-looking stewardesses, of course.  Another thing going for them is their empathy with their passengers.  I've twice been bumped up to business class (with it's better meals and basically flat sleeper beds...what an experience that is).  Once because the travel agent made a mistake and SAI decided they'd make my life a bit easier (hint: if you take the same flight 5-10 times they get to know you, too) and another time my flight was overbooked so I too business to San Francisco and got another one to Vancouver (both covered by SAI) as well as 500 Sing$ (300 USD, 350,000 won) which made for a 40% discount from my ticket price.  Anyways, this time I was in line for about 30 minutes (maybe it was longer) and a few times I squatted to relieve my legs a bit.  The gal at the counter apologized and put 2 'Solitaire' tags on my bags (will upload pic when I get back to Seoul so you can put your color printer to good use and make a few of your own) that basically put them on par with business class for unloading.  Nice.  The meals on the flight were good, there were lots of good movies and, as usual, they gave me one of those sleeper masks when I asked for it (in business it's automatic, but if you ask in economy you'll get one).  Upon arrival in Vancouver I saw a rare sight, the customs area was packed!  A cruise was in port and normal flights all bunched up to.  Not to worry, though, as just as I approached the line they opened another area of inspectors...and in about 10 minutes I was picking up my bags.  To top it off my cabbie spoke English (something that eluded me in Seoul and Vancouver much of the time) and we had a pretty cool conversation about life, marriage and cultures.  (He too believes that once you stop looking for a spouse you'll meet them...a little wisdom for you single-but-lookings out there.)  My phone can take pictures here but needs a special chip to connect.  I forgot its charger and extra battery, and already ran down the old one...so that's the only blotch on this trip so far; which ain't too bad.  I've decided to start to teach him my limited French...which should keep him on his toes.  He's already got some of the accent down when he speaks baby-talk.           \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['text'][22]  #Sample text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_x6slJkzXnuq"
   },
   "source": [
    "### Preprocessing on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aRN2T_WSriB6"
   },
   "outputs": [],
   "source": [
    "#We want to remove unwanted text from the \"text\" column, for that we use data wrangling with regular expression\n",
    "\n",
    "data1['new_text']=data1['text'].apply(lambda x: re.sub(r'[^A-Za-z]+',' ',x))  #Removing unwanted char from text using re and storing the formated text as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "I3ACqJNCZOFz"
   },
   "outputs": [],
   "source": [
    "data1['new_text']=data1['new_text'].apply(lambda x: x.lower()) #Coverting to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mP9v5VYZZODZ"
   },
   "outputs": [],
   "source": [
    "data1['new_text']=data1['new_text'].apply(lambda x: x.strip()) #removing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T40in3v2ZOAz",
    "outputId": "120e8eba-15e5-436a-ea99-0b01e3c7d15d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual text::::            These are the team members:   Drewes van der Laag           urlLink mail  Ruiyu Xie                     urlLink mail  Bryan Aaldering (me)          urlLink mail          \n"
     ]
    }
   ],
   "source": [
    "#Now lets compare our formated text and actual data\n",
    "print(\"Actual text:::: {}\".format(data1['text'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1PO0SBSZN-T",
    "outputId": "ba4ce4a1-5080-4dbf-b33b-3ff1c1086262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formated text:::: these are the team members drewes van der laag urllink mail ruiyu xie urllink mail bryan aaldering me urllink mail\n"
     ]
    }
   ],
   "source": [
    "print(\"Formated text:::: {}\".format(data1['new_text'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bSl_0uPEZN7l"
   },
   "outputs": [],
   "source": [
    "#Now lets remove stopwords from the text\n",
    "\n",
    "stopwords=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "XZE6RgmeZN4t"
   },
   "outputs": [],
   "source": [
    "data1['new_text']=data1['new_text'].apply(lambda x: ' '.join([words for words in x.split() if words not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "As0jegH1ZNrK",
    "outputId": "b9deeef5-d1af-49e3-8352-cc33acf6564b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'team members drewes van der laag urllink mail ruiyu xie urllink mail bryan aaldering urllink mail'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['new_text'][1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0EgAhH_cdqO"
   },
   "source": [
    "All the unwanted characters, stopwords and spaces are removed successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIneuZwWdKFs"
   },
   "source": [
    "Target/label merger and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WAtwlmKNcY5I"
   },
   "outputs": [],
   "source": [
    "#We need to merge all the other columns to single column(target/label column)\n",
    "data1['labels']=data1.apply(lambda col: [col['gender'],str(col['age']),col['topic'],col['sign']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "2qSQle9Erh8i",
    "outputId": "ec73b799-56c0-4021-8fd5-7465c529d267"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e0b6747d-2380-461d-9588-a4ad2b2a943a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>text</th>\n",
       "      <th>new_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0b6747d-2380-461d-9588-a4ad2b2a943a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e0b6747d-2380-461d-9588-a4ad2b2a943a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e0b6747d-2380-461d-9588-a4ad2b2a943a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  gender age              topic      sign  \\\n",
       "0   male  15            Student       Leo   \n",
       "1   male  15            Student       Leo   \n",
       "2   male  15            Student       Leo   \n",
       "3   male  15            Student       Leo   \n",
       "4   male  33  InvestmentBanking  Aquarius   \n",
       "\n",
       "                                                text  \\\n",
       "0             Info has been found (+/- 100 pages,...   \n",
       "1             These are the team members:   Drewe...   \n",
       "2             In het kader van kernfusie op aarde...   \n",
       "3                   testing!!!  testing!!!             \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...   \n",
       "\n",
       "                                            new_text  \\\n",
       "0  info found pages mb pdf files wait untill team...   \n",
       "1  team members drewes van der laag urllink mail ...   \n",
       "2  het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                    testing testing   \n",
       "4  thanks yahoo toolbar capture urls popups means...   \n",
       "\n",
       "                                    labels  \n",
       "0                 [male, 15, Student, Leo]  \n",
       "1                 [male, 15, Student, Leo]  \n",
       "2                 [male, 15, Student, Leo]  \n",
       "3                 [male, 15, Student, Leo]  \n",
       "4  [male, 33, InvestmentBanking, Aquarius]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gjp_0kkPrh5O",
    "outputId": "03c85ce6-3b72-4e5f-d1fc-f8c72eb042af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-afc50ce2-f0eb-414e-8497-a2c41d0d50df\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>info found pages mb pdf files wait untill team...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>team members drewes van der laag urllink mail ...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>testing testing</td>\n",
       "      <td>[male, 15, Student, Leo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
       "      <td>[male, 33, InvestmentBanking, Aquarius]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afc50ce2-f0eb-414e-8497-a2c41d0d50df')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-afc50ce2-f0eb-414e-8497-a2c41d0d50df button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-afc50ce2-f0eb-414e-8497-a2c41d0d50df');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            new_text  \\\n",
       "0  info found pages mb pdf files wait untill team...   \n",
       "1  team members drewes van der laag urllink mail ...   \n",
       "2  het kader van kernfusie op aarde maak je eigen...   \n",
       "3                                    testing testing   \n",
       "4  thanks yahoo toolbar capture urls popups means...   \n",
       "\n",
       "                                    labels  \n",
       "0                 [male, 15, Student, Leo]  \n",
       "1                 [male, 15, Student, Leo]  \n",
       "2                 [male, 15, Student, Leo]  \n",
       "3                 [male, 15, Student, Leo]  \n",
       "4  [male, 33, InvestmentBanking, Aquarius]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1= data1[['new_text','labels']]\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvBQoAciuXs-"
   },
   "source": [
    "### Splitting data into X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UUfDUfK3rhx5"
   },
   "outputs": [],
   "source": [
    "X = data1['new_text']\n",
    "Y = data1['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "j4-Y6zEl-iqz"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,random_state=2,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uovsNxzu-x0f",
    "outputId": "9e5564fb-eadc-4f4b-cf2d-c3563bc92819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000,)\n",
      "(8000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2M9D_WCO-xxf",
    "outputId": "feaa46a3-e8ce-4bd6-fc33-c55ee0e0787d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm5U4pM2-8pq"
   },
   "source": [
    "### Vectorize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "STVLn1Ck-xsZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "LsRW8CyXuVNr"
   },
   "outputs": [],
   "source": [
    "#Lets perform vectorization to get the count of vectors of the X data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "HFvd1ZVCuVLA"
   },
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(binary=True, ngram_range=(1,2))  #bi-gram,tri-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AXtYpcm_PUE",
    "outputId": "ee1efa99-d0b3-43ca-d70a-db7d6059aed4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533783"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(X_train)\n",
    "len(vectorizer.vocabulary_) #Vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfE5vEcY_fxh",
    "outputId": "564c8aaf-2748-4b96-e8cf-0d2aceac3029"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'aa amazing', 'aa anger', 'aa keeps', 'aa nice']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "-vZciHlyAGG4"
   },
   "outputs": [],
   "source": [
    "X_train_ct = vectorizer.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "auA6BdJ6AGEQ",
    "outputId": "9752a697-e4de-4f73-9ed5-d46fba3cf7b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x533783 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 316 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_ct)\n",
    "X_train_ct[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "qhbujnUfAYEa"
   },
   "outputs": [],
   "source": [
    "X_test_ct = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Svq-y-BFAYBo",
    "outputId": "6628bee8-5749-4d92-b09d-6c704c554cda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'aa amazing', 'aa anger', 'aa keeps', 'aa nice']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "B6tEaRgBAX-5"
   },
   "outputs": [],
   "source": [
    "#Creating a dictionary to get the count of evert label\n",
    "label_counts=dict()\n",
    "\n",
    "for labels in data1.labels.values:\n",
    "    for label in labels:\n",
    "        if label in label_counts:\n",
    "            label_counts[label]+=1\n",
    "        else:\n",
    "            label_counts[label]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVhZbwUiAGBd",
    "outputId": "de9dc53f-257c-4f82-fdd1-dd1d0fd59f87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'13': 42,\n",
       " '14': 212,\n",
       " '15': 602,\n",
       " '16': 440,\n",
       " '17': 1185,\n",
       " '23': 253,\n",
       " '24': 655,\n",
       " '25': 386,\n",
       " '26': 234,\n",
       " '27': 1054,\n",
       " '33': 136,\n",
       " '34': 553,\n",
       " '35': 2315,\n",
       " '36': 1708,\n",
       " '37': 33,\n",
       " '38': 46,\n",
       " '39': 79,\n",
       " '40': 1,\n",
       " '41': 20,\n",
       " '42': 14,\n",
       " '43': 6,\n",
       " '44': 3,\n",
       " '45': 16,\n",
       " '46': 7,\n",
       " 'Accounting': 4,\n",
       " 'Aquarius': 571,\n",
       " 'Aries': 4198,\n",
       " 'Arts': 45,\n",
       " 'Automotive': 14,\n",
       " 'Banking': 16,\n",
       " 'BusinessServices': 91,\n",
       " 'Cancer': 504,\n",
       " 'Capricorn': 215,\n",
       " 'Communications-Media': 99,\n",
       " 'Consulting': 21,\n",
       " 'Education': 270,\n",
       " 'Engineering': 127,\n",
       " 'Fashion': 1622,\n",
       " 'Gemini': 150,\n",
       " 'HumanResources': 2,\n",
       " 'Internet': 118,\n",
       " 'InvestmentBanking': 70,\n",
       " 'Law': 11,\n",
       " 'LawEnforcement-Security': 10,\n",
       " 'Leo': 301,\n",
       " 'Libra': 491,\n",
       " 'Marketing': 156,\n",
       " 'Museums-Libraries': 17,\n",
       " 'Non-Profit': 71,\n",
       " 'Pisces': 454,\n",
       " 'Publishing': 4,\n",
       " 'Religion': 9,\n",
       " 'Sagittarius': 1097,\n",
       " 'Science': 63,\n",
       " 'Scorpio': 971,\n",
       " 'Sports-Recreation': 80,\n",
       " 'Student': 1137,\n",
       " 'Taurus': 812,\n",
       " 'Technology': 2654,\n",
       " 'Telecommunications': 2,\n",
       " 'Virgo': 236,\n",
       " 'female': 4084,\n",
       " 'indUnk': 3287,\n",
       " 'male': 5916}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOg_TbuMC4EB"
   },
   "source": [
    "Transforming the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "kXbOW9ziCxH_"
   },
   "outputs": [],
   "source": [
    "#Lets preprocess the labels\n",
    "\n",
    "binarizer=MultiLabelBinarizer(classes=sorted(label_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "tTpOr8XZCxCZ"
   },
   "outputs": [],
   "source": [
    "Y_train = binarizer.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "96CYbiMrCw_d"
   },
   "outputs": [],
   "source": [
    "Y_test = binarizer.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFF0T8HtCw8a",
    "outputId": "62c01723-12fa-4b6b-a591-70662a78382b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAisjOh1DY2T",
    "outputId": "71fc1712-bfa7-47be-c948-c8943ad5b395"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CN0JlxcDfhl"
   },
   "source": [
    "### We need to choose a classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "X3Nw8w9lDfNM"
   },
   "outputs": [],
   "source": [
    "#For this problem we are using OneVsRestClassifier,and for basic classifier we are using LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSKwx0_0DfKn",
    "outputId": "412974ae-cad0-4b36-fdf2-2d50b131d82c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(solver='lbfgs', max_iter=100)\n",
    "model=OneVsRestClassifier(model)\n",
    "model.fit(X_train_ct,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "Gj2iRoEmDfHj"
   },
   "outputs": [],
   "source": [
    "Y_pred=model.predict(X_test_ct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GiiglGRYDfEk",
    "outputId": "a771dd57-a5a2-4414-f384-6a6763e9cc9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NyLC1KpfDfBr",
    "outputId": "33a447dd-eee8-4fce-f931-a6e0bf8c3b2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8N6TFqlhFg8i"
   },
   "source": [
    "### Display and explain detail the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "PuDsVpQlE4ao"
   },
   "outputs": [],
   "source": [
    "#Here we are using the micro and  Macro-average method. It takes the average of the precision and recall of the different sets\n",
    "\n",
    "\n",
    "def display_metrics_micro(Y_test, Y_pred):\n",
    "    print('Accuracy score: ', accuracy_score(Y_test, Y_pred))\n",
    "    print('F1 score: Micro', f1_score(Y_test, Y_pred, average='micro'))\n",
    "    print('Average precision score: Micro', average_precision_score(Y_test, Y_pred, average='micro'))\n",
    "    print('Average recall score: Micro', recall_score(Y_test, Y_pred, average='micro'))\n",
    "    \n",
    "    \n",
    "def display_metrics_macro(Y_test, Y_pred):\n",
    "    print('Accuracy score: ', accuracy_score(Y_test, Y_pred))\n",
    "    print('F1 score: Macro', f1_score(Y_test, Y_pred, average='macro'))\n",
    "    print('Average recall score: Macro', recall_score(Y_test, Y_pred, average='macro'))\n",
    "    \n",
    "def display_metrics_weighted(Y_test, Y_pred):\n",
    "    print('Accuracy score: ', accuracy_score(Y_test, Y_pred))\n",
    "    print('F1 score: weighted', f1_score(Y_test, Y_pred, average='weighted'))\n",
    "    print('Average precision score: weighted', average_precision_score(Y_test, Y_pred, average='weighted'))\n",
    "    print('Average recall score: weighted', recall_score(Y_test, Y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7Xqy-uiE4YA",
    "outputId": "dd021305-e0b0-45ea-a0e7-83d75ccbf291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.327\n",
      "F1 score: Micro 0.6424971793907484\n",
      "Average precision score: Micro 0.45976173129131254\n",
      "Average recall score: Micro 0.533875\n"
     ]
    }
   ],
   "source": [
    "display_metrics_micro(Y_test,Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GKuwx1RoE4V1",
    "outputId": "c5f0c288-9e5e-4642-d434-eb1be73fe781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.327\n",
      "F1 score: Macro 0.2313766894433141\n",
      "Average recall score: Macro 0.17428093502655756\n"
     ]
    }
   ],
   "source": [
    "display_metrics_macro(Y_test,Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7h2TMN1E4S8",
    "outputId": "8a0ac409-98f1-41a8-b580-bec0ab2cd6c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.327\n",
      "F1 score: weighted 0.5954162143427103\n",
      "Average precision score: weighted 0.5135626619782332\n",
      "Average recall score: weighted 0.533875\n"
     ]
    }
   ],
   "source": [
    "display_metrics_weighted(Y_test,Y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ronr8m24HAKN"
   },
   "source": [
    "The classification report displays the accuarcy F1 score,precision & recall score for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEMrEyusHBHe"
   },
   "source": [
    "### Print the true vs predicted labels for any 5 entries from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "pF2v9w9fE4QJ"
   },
   "outputs": [],
   "source": [
    "preds = Y_pred[:15]\n",
    "actuals = Y_test[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kKB17F2T7mEV",
    "outputId": "16251d34-ca3e-421f-9005-66b6c4898694"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('36', 'Aries', 'Fashion', 'male'),\n",
       " ('35', 'Aries', 'Technology', 'male'),\n",
       " ('35', 'Aries', 'Technology', 'male'),\n",
       " ('34', 'Sagittarius', 'female', 'indUnk'),\n",
       " ('42', 'Consulting', 'Leo', 'female'),\n",
       " ('17', 'Scorpio', 'female', 'indUnk'),\n",
       " ('36', 'Aries', 'Fashion', 'male'),\n",
       " ('35', 'Aries', 'Technology', 'male'),\n",
       " ('35', 'Aries', 'Technology', 'male'),\n",
       " ('34', 'Sagittarius', 'female', 'indUnk'),\n",
       " ('36', 'Aries', 'Fashion', 'male'),\n",
       " ('35', 'Aries', 'Technology', 'male'),\n",
       " ('35', 'Aries', 'Technology', 'male'),\n",
       " ('39', 'Communications-Media', 'Libra', 'male'),\n",
       " ('36', 'Aries', 'Fashion', 'male')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_actual = binarizer.inverse_transform(actuals)\n",
    "five_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dMCZXs6E7mB8",
    "outputId": "c7f9ecab-22ed-4db8-e5ec-27483660ca90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('male',),\n",
       " ('female',),\n",
       " ('Technology', 'male'),\n",
       " ('34', 'Sagittarius', 'female', 'indUnk'),\n",
       " ('female', 'indUnk'),\n",
       " ('17', 'Scorpio', 'female', 'indUnk'),\n",
       " ('36', 'Aries', 'Fashion', 'male'),\n",
       " ('Aries', 'male'),\n",
       " ('Aries', 'male'),\n",
       " ('34', 'Sagittarius', 'female', 'indUnk'),\n",
       " ('35', 'Aries', 'Technology', 'male'),\n",
       " ('Aries', 'male'),\n",
       " ('male',),\n",
       " ('indUnk', 'male'),\n",
       " ('Aries', 'male')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_pred = binarizer.inverse_transform(preds)\n",
    "five_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kmt1bpaf7l_X",
    "outputId": "3f09b4e7-178f-4b29-83e5-6f00788fa9da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('male',)\n",
      "('35', 'Aries', 'Technology', 'male')\n"
     ]
    }
   ],
   "source": [
    "print(binarizer.inverse_transform(Y_pred)[500])\n",
    "print(binarizer.inverse_transform(Y_test)[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EkWI6Tbt7l8k",
    "outputId": "aeb24eb7-8ea6-4727-e359-ecd432e4bdf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('36', 'Aries', 'Fashion', 'male')\n",
      "('36', 'Aries', 'Fashion', 'male')\n"
     ]
    }
   ],
   "source": [
    "print(binarizer.inverse_transform(Y_pred)[400])\n",
    "print(binarizer.inverse_transform(Y_test)[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1w5uQP6u7l6H",
    "outputId": "3fb5db2a-7501-49f0-a1eb-2ed2bee745ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('27', '36', 'Fashion', 'female', 'indUnk')\n",
      "('36', 'Aries', 'Fashion', 'male')\n"
     ]
    }
   ],
   "source": [
    "print(binarizer.inverse_transform(Y_pred)[450])\n",
    "print(binarizer.inverse_transform(Y_test)[450])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RrbQUqid7l3l",
    "outputId": "2d904f26-c793-4d6d-dfe1-100939543cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('male',)\n",
      "('16', 'Libra', 'Student', 'female')\n"
     ]
    }
   ],
   "source": [
    "print(binarizer.inverse_transform(Y_pred)[333])\n",
    "print(binarizer.inverse_transform(Y_test)[333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8TuKb1E7l09",
    "outputId": "942aab58-06ca-400d-94c0-dc2e59903076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sagittarius', 'female', 'indUnk')\n",
      "('34', 'Sagittarius', 'female', 'indUnk')\n"
     ]
    }
   ],
   "source": [
    "print(binarizer.inverse_transform(Y_pred)[666])\n",
    "print(binarizer.inverse_transform(Y_test)[666])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C2Rw2s6T7eO"
   },
   "source": [
    "## <u>Part Two - PROJECT BASED </u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlSoxbn4rw0h"
   },
   "source": [
    "• <b>DOMAIN:</b>  Customer support\n",
    "\n",
    "• <b>CONTEXT:</b> : Great Learning has a an academic support department which receives numerous support requests every day throughout the\n",
    "year. Teams are spread across geographies and try to provide support round the year. Sometimes there are circumstances where due to\n",
    "heavy workload certain request resolutions are delayed, impacting company’s business. Some of the requests are very generic where a\n",
    "proper resolution procedure delivered to the user can solve the problem. Company is looking forward to design an automation which can\n",
    "interact with the user, understand the problem and display the resolution procedure [ if found as a generic request ] or redirect the request\n",
    "to an actual human support executive if the request is complex or not in it’s database.\n",
    "\n",
    "• <b>DATA DESCRIPTION:</b>  A sample corpus is attached for your reference. Please enhance/add more data to the corpus using your linguistics\n",
    "skills.<br>\n",
    "\n",
    "• <b>PROJECT OBJECTIVE:</b> : Design a python based interactive semi - rule based chatbot which can do the following:\n",
    "\n",
    "1. Start chat session with greetings and ask what the user is looking for.\n",
    "2. Accept dynamic text based questions from the user. Reply back with relevant answer from the designed corpus.<br>\n",
    "3. End the chat session only if the user requests to end else ask what the user is looking for. Loop continues till the user asks to end it..<br>\n",
    "   \n",
    "• <b>EVALUATION</b>:  GL evaluator will use linguistics to twist and turn sentences to ask questions on the topics described in <b>DATA DESCRIPTION</b>\n",
    "and check if the bot is giving relevant replies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "FDXq-J46apYY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wxr14KFkz7s8"
   },
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u0dkko80z90R",
    "outputId": "35b20c3c-ed62-4ff5-8ac4-247f088113a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# install specific downloads\n",
    "nltk.download('punkt', quiet = True)\n",
    "nltk.download('wordnet', quiet = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "V8yEby_mABip"
   },
   "outputs": [],
   "source": [
    "#imporitng the corpus\n",
    "data_file = open(\"/content/drive/MyDrive/AIML/Labs/CV/GL Bot.json\").read()\n",
    "intents  = json.loads(data_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CJS03cL-HLP4",
    "outputId": "403bb6e8-c6c3-4279-9181-e6fd0e2cd85d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intents': [{'context_set': '',\n",
       "   'patterns': ['hi',\n",
       "    'how are you',\n",
       "    'is anyone there',\n",
       "    'hello',\n",
       "    'whats up',\n",
       "    'hey',\n",
       "    'yo',\n",
       "    'listen',\n",
       "    'please help me',\n",
       "    'i am learner from',\n",
       "    'i belong to',\n",
       "    'aiml batch',\n",
       "    'aifl batch',\n",
       "    'i am from',\n",
       "    'my pm is',\n",
       "    'blended',\n",
       "    'online',\n",
       "    'i am from',\n",
       "    'hey ya',\n",
       "    'talking to you for first time'],\n",
       "   'responses': ['Hello! how can i help you ?'],\n",
       "   'tag': 'Intro'},\n",
       "  {'context_set': '',\n",
       "   'patterns': ['thank you',\n",
       "    'thanks',\n",
       "    'cya',\n",
       "    'see you',\n",
       "    'later',\n",
       "    'see you later',\n",
       "    'goodbye',\n",
       "    'i am leaving',\n",
       "    'have a Good day',\n",
       "    'you helped me',\n",
       "    'thanks a lot',\n",
       "    'thanks a ton',\n",
       "    'you are the best',\n",
       "    'great help',\n",
       "    'too good',\n",
       "    'you are a good learning buddy'],\n",
       "   'responses': ['I hope I was able to assist you, Good Bye'],\n",
       "   'tag': 'Exit'},\n",
       "  {'context_set': '',\n",
       "   'patterns': ['olympus',\n",
       "    'explain me how olympus works',\n",
       "    'I am not able to understand olympus',\n",
       "    'olympus window not working',\n",
       "    'no access to olympus',\n",
       "    'unable to see link in olympus',\n",
       "    'no link visible on olympus',\n",
       "    'whom to contact for olympus',\n",
       "    'lot of problem with olympus',\n",
       "    'olypus is not a good tool',\n",
       "    'lot of problems with olympus',\n",
       "    'how to use olympus',\n",
       "    'teach me olympus'],\n",
       "   'responses': ['Link: Olympus wiki'],\n",
       "   'tag': 'Olympus'},\n",
       "  {'context_set': '',\n",
       "   'patterns': ['i am not able to understand svm',\n",
       "    'explain me how machine learning works',\n",
       "    'i am not able to understand naive bayes',\n",
       "    'i am not able to understand logistic regression',\n",
       "    'i am not able to understand ensemble techb=niques',\n",
       "    'i am not able to understand knn',\n",
       "    'i am not able to understand knn imputer',\n",
       "    'i am not able to understand cross validation',\n",
       "    'i am not able to understand boosting',\n",
       "    'i am not able to understand random forest',\n",
       "    'i am not able to understand ada boosting',\n",
       "    'i am not able to understand gradient boosting',\n",
       "    'machine learning',\n",
       "    'ML',\n",
       "    'SL',\n",
       "    'supervised learning',\n",
       "    'knn',\n",
       "    'logistic regression',\n",
       "    'regression',\n",
       "    'classification',\n",
       "    'naive bayes',\n",
       "    'nb',\n",
       "    'ensemble techniques',\n",
       "    'bagging',\n",
       "    'boosting',\n",
       "    'ada boosting',\n",
       "    'ada',\n",
       "    'gradient boosting',\n",
       "    'hyper parameters'],\n",
       "   'responses': ['Link: Machine Learning wiki '],\n",
       "   'tag': 'SL'},\n",
       "  {'context_set': '',\n",
       "   'patterns': ['what is deep learning',\n",
       "    'unable to understand deep learning',\n",
       "    'explain me how deep learning works',\n",
       "    'i am not able to understand deep learning',\n",
       "    'not able to understand neural nets',\n",
       "    'very diffult to understand neural nets',\n",
       "    'unable to understand neural nets',\n",
       "    'ann',\n",
       "    'artificial intelligence',\n",
       "    'artificial neural networks',\n",
       "    'weights',\n",
       "    'activation function',\n",
       "    'hidden layers',\n",
       "    'softmax',\n",
       "    'sigmoid',\n",
       "    'relu',\n",
       "    'otimizer',\n",
       "    'forward propagation',\n",
       "    'backward propagation',\n",
       "    'epochs',\n",
       "    'epoch',\n",
       "    'what is an epoch',\n",
       "    'adam',\n",
       "    'sgd'],\n",
       "   'responses': ['Link: Neural Nets wiki'],\n",
       "   'tag': 'NN'},\n",
       "  {'context_set': '',\n",
       "   'patterns': ['what is your name',\n",
       "    'who are you',\n",
       "    'name please',\n",
       "    'when are your hours of opertions',\n",
       "    'what are your working hours',\n",
       "    'hours of operation',\n",
       "    'working hours',\n",
       "    'hours'],\n",
       "   'responses': ['I am your virtual learning assistant'],\n",
       "   'tag': 'Bot'},\n",
       "  {'context_set': '',\n",
       "   'patterns': ['what the hell',\n",
       "    'bloody stupid bot',\n",
       "    'do you think you are very smart',\n",
       "    'screw you',\n",
       "    'i hate you',\n",
       "    'you are stupid',\n",
       "    'jerk',\n",
       "    'you are a joke',\n",
       "    'useless piece of shit'],\n",
       "   'responses': ['Please use respectful words'],\n",
       "   'tag': 'Profane'},\n",
       "  {'context_set': '',\n",
       "   'patterns': ['my problem is not solved',\n",
       "    'you did not help me',\n",
       "    'not a good solution',\n",
       "    'bad solution',\n",
       "    'not good solution',\n",
       "    'no help',\n",
       "    'wasted my time',\n",
       "    'useless bot',\n",
       "    'create a ticket'],\n",
       "   'responses': ['Tarnsferring the request to your PM'],\n",
       "   'tag': 'Ticket'}]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents #Displaying the corpus, it is dictionay with keys and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_y2edfSOp-u",
    "outputId": "e79de42b-1dec-4848-bd20-3c4277f5e9e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tag', 'patterns', 'responses', 'context_set'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents['intents'][0].keys() #From above and this line we can see we have common inner keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjsmYCbEPllx",
    "outputId": "5a25c7ff-96f1-4700-d8f4-c00e7d2cf202"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Intro', ['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time'], ['Hello! how can i help you ?'], ''])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents['intents'][0].values() #Since it is nested dictionary we can see these are there are values under each sub keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HuwyMznyP7WX",
    "outputId": "85c37aba-3551-45ac-ed0a-2ca9eb7e984b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intro\n",
      "['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time']\n",
      "['Hello! how can i help you ?']\n"
     ]
    }
   ],
   "source": [
    "print(intents['intents'][0]['tag'])\n",
    "print(intents['intents'][0]['patterns'])\n",
    "print(intents['intents'][0]['responses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uW4Ny1wVQPqK"
   },
   "source": [
    "These kind of key value pair are present in this corpus for our chatbot.\n",
    "Now we can add little more data to the corpus using our linguistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnjQ-FtjQhGK",
    "outputId": "30ad91c5-e420-41bf-e126-d8828991fca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi',\n",
       " 'how are you',\n",
       " 'is anyone there',\n",
       " 'hello',\n",
       " 'whats up',\n",
       " 'hey',\n",
       " 'yo',\n",
       " 'listen',\n",
       " 'please help me',\n",
       " 'i am learner from',\n",
       " 'i belong to',\n",
       " 'aiml batch',\n",
       " 'aifl batch',\n",
       " 'i am from',\n",
       " 'my pm is',\n",
       " 'blended',\n",
       " 'online',\n",
       " 'i am from',\n",
       " 'hey ya',\n",
       " 'talking to you for first time',\n",
       " 'greetings',\n",
       " 'howdy',\n",
       " 'welcome',\n",
       " 'good morning',\n",
       " 'hi ya',\n",
       " 'how goes it',\n",
       " 'howdy do',\n",
       " 'whats happening']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_tag = ['greetings','howdy','welcome','good morning','hi ya','how goes it','howdy do','whats happening']  #list of values adding to the intro tag\n",
    "intents['intents'][0]['patterns'] += intro_tag #Appending the list\n",
    "intents['intents'][0]['patterns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnmJjCjNQhDu",
    "outputId": "112e59e9-ccdb-4036-95c4-8190c3b5e771"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thank you',\n",
       " 'thanks',\n",
       " 'cya',\n",
       " 'see you',\n",
       " 'later',\n",
       " 'see you later',\n",
       " 'goodbye',\n",
       " 'i am leaving',\n",
       " 'have a Good day',\n",
       " 'you helped me',\n",
       " 'thanks a lot',\n",
       " 'thanks a ton',\n",
       " 'you are the best',\n",
       " 'great help',\n",
       " 'too good',\n",
       " 'you are a good learning buddy',\n",
       " 'bye',\n",
       " 'quit',\n",
       " 'exit',\n",
       " 'end',\n",
       " 'stop',\n",
       " 'take care',\n",
       " 'good day',\n",
       " 'so long',\n",
       " 'godspeed',\n",
       " 'farewell',\n",
       " 'ta ta',\n",
       " 'pause',\n",
       " 'mute',\n",
       " 'finish',\n",
       " 'cease',\n",
       " 'halt',\n",
       " 'terminate',\n",
       " 'wind up']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exit_tag = ['bye','quit','exit','end','stop','take care','good day','so long','godspeed','farewell','ta ta','pause','mute','finish','cease','halt','terminate','wind up']\n",
    "intents['intents'][1]['patterns'] += exit_tag #Appending the list\n",
    "intents['intents'][1]['patterns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "FJW6Er9xQhBM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "iP67VOhpABgQ"
   },
   "outputs": [],
   "source": [
    "ignore_punctuation = [\"?\", \"!\", \".\", \",\"] #Ignoring unwanted char\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Z789B_8fABdu"
   },
   "outputs": [],
   "source": [
    "def process_words(pattern):\n",
    "    # return variable\n",
    "    words = []\n",
    "    # get the tokens using nltk\n",
    "    tokens = nltk.word_tokenize(pattern)\n",
    "    for word in tokens:\n",
    "        # check if the word should be ignored\n",
    "        if word not in ignore_punctuation and word.isalnum():\n",
    "            # clean the word and add it to the list\n",
    "            cleaned_word = lemmatizer.lemmatize(word.lower())\n",
    "            words.append(cleaned_word)\n",
    "    # return the list\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "UE_YesXeABWr"
   },
   "outputs": [],
   "source": [
    "def parse_intents(intents):\n",
    "    # declare our needed variables\n",
    "    tags = []\n",
    "    all_words = []\n",
    "    tag_tokens = []\n",
    "    response_dict = dict()\n",
    "    \n",
    "    # iterate through each intent\n",
    "    for intent in intents[\"intents\"]:\n",
    "        \n",
    "        # add the noanswer tag to the dictionary (edge case)\n",
    "        if (intent[\"tag\"] == \"noanswer\"):\n",
    "            response_dict[\"noanswer\"] = intent[\"responses\"]\n",
    "        \n",
    "        # if the intent has no patterns, we can skip\n",
    "        if (len(intent[\"patterns\"]) == 0):\n",
    "            continue\n",
    "        \n",
    "        # add the tag to the list of tag\n",
    "        tag = intent[\"tag\"]\n",
    "        tags.append(tag)\n",
    "        \n",
    "        # update the dictionary\n",
    "        response_dict[tag] = intent[\"responses\"]\n",
    "        \n",
    "        # iterate through each pattern\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            # create our tokenized words\n",
    "            tokenized_words = process_words(pattern)\n",
    "            # add all the tokenized words to our words\n",
    "            all_words.extend(tokenized_words)\n",
    "            # adds a tuple -> (list of tokens, tag) -> to the list\n",
    "            tag_tokens.append((tokenized_words, tag))      \n",
    "    \n",
    "    # return our values in a tuple\n",
    "    return (np.array(tags), np.array(all_words), np.array(tag_tokens), response_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "qWGhRj0OABS0"
   },
   "outputs": [],
   "source": [
    "# call our function\n",
    "tags, all_words, tag_tokens, tag_responses = parse_intents(intents)\n",
    "# sort and remove duplicates\n",
    "tags = np.array(sorted(list(set(tags))))\n",
    "all_words = np.array(sorted(list(set(all_words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KomjJzX8ABQB",
    "outputId": "d732e05e-daa9-4524-d2a4-e84f73ab6d24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags: ['Bot' 'Exit' 'Intro' 'NN' 'Olympus' 'Profane' 'SL' 'Ticket']\n",
      "------\n",
      "All Words: ['a' 'able' 'access' 'activation' 'ada' 'adam' 'aifl' 'aiml' 'am' 'an'\n",
      " 'ann' 'anyone' 'are' 'artificial' 'backward' 'bad' 'bagging' 'batch'\n",
      " 'bayes' 'belong' 'best' 'blended' 'bloody' 'boosting' 'bot' 'buddy' 'bye'\n",
      " 'care' 'cease' 'classification' 'contact' 'create' 'cross' 'cya' 'day'\n",
      " 'deep' 'did' 'diffult' 'do' 'end' 'ensemble' 'epoch' 'exit' 'explain'\n",
      " 'farewell' 'finish' 'first' 'for' 'forest' 'forward' 'from' 'function'\n",
      " 'go' 'godspeed' 'good' 'goodbye' 'gradient' 'great' 'greeting' 'halt'\n",
      " 'happening' 'hate' 'have' 'hell' 'hello' 'help' 'helped' 'hey' 'hi'\n",
      " 'hidden' 'hour' 'how' 'howdy' 'hyper' 'i' 'imputer' 'in' 'intelligence'\n",
      " 'is' 'it' 'jerk' 'joke' 'knn' 'later' 'layer' 'learner' 'learning'\n",
      " 'leaving' 'link' 'listen' 'logistic' 'long' 'lot' 'machine' 'me' 'ml'\n",
      " 'morning' 'mute' 'my' 'naive' 'name' 'nb' 'net' 'network' 'neural' 'no'\n",
      " 'not' 'of' 'olympus' 'olypus' 'on' 'online' 'operation' 'opertions'\n",
      " 'otimizer' 'parameter' 'pause' 'piece' 'please' 'pm' 'problem'\n",
      " 'propagation' 'quit' 'random' 'regression' 'relu' 'screw' 'see' 'sgd'\n",
      " 'shit' 'sigmoid' 'sl' 'smart' 'so' 'softmax' 'solution' 'solved' 'stop'\n",
      " 'stupid' 'supervised' 'svm' 'ta' 'take' 'talking' 'teach' 'technique'\n",
      " 'terminate' 'thank' 'thanks' 'the' 'there' 'think' 'ticket' 'time' 'to'\n",
      " 'ton' 'too' 'tool' 'unable' 'understand' 'up' 'use' 'useless'\n",
      " 'validation' 'very' 'visible' 'wasted' 'weight' 'welcome' 'what' 'whats'\n",
      " 'when' 'who' 'whom' 'wind' 'window' 'with' 'work' 'working' 'ya' 'yo'\n",
      " 'you' 'your']\n",
      "------\n",
      "Tag-Token Mappings: [[list(['hi']) 'Intro']\n",
      " [list(['how', 'are', 'you']) 'Intro']\n",
      " [list(['is', 'anyone', 'there']) 'Intro']\n",
      " [list(['hello']) 'Intro']\n",
      " [list(['whats', 'up']) 'Intro']\n",
      " [list(['hey']) 'Intro']\n",
      " [list(['yo']) 'Intro']\n",
      " [list(['listen']) 'Intro']\n",
      " [list(['please', 'help', 'me']) 'Intro']\n",
      " [list(['i', 'am', 'learner', 'from']) 'Intro']\n",
      " [list(['i', 'belong', 'to']) 'Intro']\n",
      " [list(['aiml', 'batch']) 'Intro']\n",
      " [list(['aifl', 'batch']) 'Intro']\n",
      " [list(['i', 'am', 'from']) 'Intro']\n",
      " [list(['my', 'pm', 'is']) 'Intro']\n",
      " [list(['blended']) 'Intro']\n",
      " [list(['online']) 'Intro']\n",
      " [list(['i', 'am', 'from']) 'Intro']\n",
      " [list(['hey', 'ya']) 'Intro']\n",
      " [list(['talking', 'to', 'you', 'for', 'first', 'time']) 'Intro']\n",
      " [list(['greeting']) 'Intro']\n",
      " [list(['howdy']) 'Intro']\n",
      " [list(['welcome']) 'Intro']\n",
      " [list(['good', 'morning']) 'Intro']\n",
      " [list(['hi', 'ya']) 'Intro']\n",
      " [list(['how', 'go', 'it']) 'Intro']\n",
      " [list(['howdy', 'do']) 'Intro']\n",
      " [list(['whats', 'happening']) 'Intro']\n",
      " [list(['thank', 'you']) 'Exit']\n",
      " [list(['thanks']) 'Exit']\n",
      " [list(['cya']) 'Exit']\n",
      " [list(['see', 'you']) 'Exit']\n",
      " [list(['later']) 'Exit']\n",
      " [list(['see', 'you', 'later']) 'Exit']\n",
      " [list(['goodbye']) 'Exit']\n",
      " [list(['i', 'am', 'leaving']) 'Exit']\n",
      " [list(['have', 'a', 'good', 'day']) 'Exit']\n",
      " [list(['you', 'helped', 'me']) 'Exit']\n",
      " [list(['thanks', 'a', 'lot']) 'Exit']\n",
      " [list(['thanks', 'a', 'ton']) 'Exit']\n",
      " [list(['you', 'are', 'the', 'best']) 'Exit']\n",
      " [list(['great', 'help']) 'Exit']\n",
      " [list(['too', 'good']) 'Exit']\n",
      " [list(['you', 'are', 'a', 'good', 'learning', 'buddy']) 'Exit']\n",
      " [list(['bye']) 'Exit']\n",
      " [list(['quit']) 'Exit']\n",
      " [list(['exit']) 'Exit']\n",
      " [list(['end']) 'Exit']\n",
      " [list(['stop']) 'Exit']\n",
      " [list(['take', 'care']) 'Exit']\n",
      " [list(['good', 'day']) 'Exit']\n",
      " [list(['so', 'long']) 'Exit']\n",
      " [list(['godspeed']) 'Exit']\n",
      " [list(['farewell']) 'Exit']\n",
      " [list(['ta', 'ta']) 'Exit']\n",
      " [list(['pause']) 'Exit']\n",
      " [list(['mute']) 'Exit']\n",
      " [list(['finish']) 'Exit']\n",
      " [list(['cease']) 'Exit']\n",
      " [list(['halt']) 'Exit']\n",
      " [list(['terminate']) 'Exit']\n",
      " [list(['wind', 'up']) 'Exit']\n",
      " [list(['olympus']) 'Olympus']\n",
      " [list(['explain', 'me', 'how', 'olympus', 'work']) 'Olympus']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'olympus'])\n",
      "  'Olympus']\n",
      " [list(['olympus', 'window', 'not', 'working']) 'Olympus']\n",
      " [list(['no', 'access', 'to', 'olympus']) 'Olympus']\n",
      " [list(['unable', 'to', 'see', 'link', 'in', 'olympus']) 'Olympus']\n",
      " [list(['no', 'link', 'visible', 'on', 'olympus']) 'Olympus']\n",
      " [list(['whom', 'to', 'contact', 'for', 'olympus']) 'Olympus']\n",
      " [list(['lot', 'of', 'problem', 'with', 'olympus']) 'Olympus']\n",
      " [list(['olypus', 'is', 'not', 'a', 'good', 'tool']) 'Olympus']\n",
      " [list(['lot', 'of', 'problem', 'with', 'olympus']) 'Olympus']\n",
      " [list(['how', 'to', 'use', 'olympus']) 'Olympus']\n",
      " [list(['teach', 'me', 'olympus']) 'Olympus']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'svm']) 'SL']\n",
      " [list(['explain', 'me', 'how', 'machine', 'learning', 'work']) 'SL']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'naive', 'bayes'])\n",
      "  'SL']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'logistic', 'regression'])\n",
      "  'SL']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'ensemble']) 'SL']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'knn']) 'SL']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'knn', 'imputer'])\n",
      "  'SL']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'cross', 'validation'])\n",
      "  'SL']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'boosting']) 'SL']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'random', 'forest'])\n",
      "  'SL']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'ada', 'boosting'])\n",
      "  'SL']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'gradient', 'boosting'])\n",
      "  'SL']\n",
      " [list(['machine', 'learning']) 'SL']\n",
      " [list(['ml']) 'SL']\n",
      " [list(['sl']) 'SL']\n",
      " [list(['supervised', 'learning']) 'SL']\n",
      " [list(['knn']) 'SL']\n",
      " [list(['logistic', 'regression']) 'SL']\n",
      " [list(['regression']) 'SL']\n",
      " [list(['classification']) 'SL']\n",
      " [list(['naive', 'bayes']) 'SL']\n",
      " [list(['nb']) 'SL']\n",
      " [list(['ensemble', 'technique']) 'SL']\n",
      " [list(['bagging']) 'SL']\n",
      " [list(['boosting']) 'SL']\n",
      " [list(['ada', 'boosting']) 'SL']\n",
      " [list(['ada']) 'SL']\n",
      " [list(['gradient', 'boosting']) 'SL']\n",
      " [list(['hyper', 'parameter']) 'SL']\n",
      " [list(['what', 'is', 'deep', 'learning']) 'NN']\n",
      " [list(['unable', 'to', 'understand', 'deep', 'learning']) 'NN']\n",
      " [list(['explain', 'me', 'how', 'deep', 'learning', 'work']) 'NN']\n",
      " [list(['i', 'am', 'not', 'able', 'to', 'understand', 'deep', 'learning'])\n",
      "  'NN']\n",
      " [list(['not', 'able', 'to', 'understand', 'neural', 'net']) 'NN']\n",
      " [list(['very', 'diffult', 'to', 'understand', 'neural', 'net']) 'NN']\n",
      " [list(['unable', 'to', 'understand', 'neural', 'net']) 'NN']\n",
      " [list(['ann']) 'NN']\n",
      " [list(['artificial', 'intelligence']) 'NN']\n",
      " [list(['artificial', 'neural', 'network']) 'NN']\n",
      " [list(['weight']) 'NN']\n",
      " [list(['activation', 'function']) 'NN']\n",
      " [list(['hidden', 'layer']) 'NN']\n",
      " [list(['softmax']) 'NN']\n",
      " [list(['sigmoid']) 'NN']\n",
      " [list(['relu']) 'NN']\n",
      " [list(['otimizer']) 'NN']\n",
      " [list(['forward', 'propagation']) 'NN']\n",
      " [list(['backward', 'propagation']) 'NN']\n",
      " [list(['epoch']) 'NN']\n",
      " [list(['epoch']) 'NN']\n",
      " [list(['what', 'is', 'an', 'epoch']) 'NN']\n",
      " [list(['adam']) 'NN']\n",
      " [list(['sgd']) 'NN']\n",
      " [list(['what', 'is', 'your', 'name']) 'Bot']\n",
      " [list(['who', 'are', 'you']) 'Bot']\n",
      " [list(['name', 'please']) 'Bot']\n",
      " [list(['when', 'are', 'your', 'hour', 'of', 'opertions']) 'Bot']\n",
      " [list(['what', 'are', 'your', 'working', 'hour']) 'Bot']\n",
      " [list(['hour', 'of', 'operation']) 'Bot']\n",
      " [list(['working', 'hour']) 'Bot']\n",
      " [list(['hour']) 'Bot']\n",
      " [list(['what', 'the', 'hell']) 'Profane']\n",
      " [list(['bloody', 'stupid', 'bot']) 'Profane']\n",
      " [list(['do', 'you', 'think', 'you', 'are', 'very', 'smart']) 'Profane']\n",
      " [list(['screw', 'you']) 'Profane']\n",
      " [list(['i', 'hate', 'you']) 'Profane']\n",
      " [list(['you', 'are', 'stupid']) 'Profane']\n",
      " [list(['jerk']) 'Profane']\n",
      " [list(['you', 'are', 'a', 'joke']) 'Profane']\n",
      " [list(['useless', 'piece', 'of', 'shit']) 'Profane']\n",
      " [list(['my', 'problem', 'is', 'not', 'solved']) 'Ticket']\n",
      " [list(['you', 'did', 'not', 'help', 'me']) 'Ticket']\n",
      " [list(['not', 'a', 'good', 'solution']) 'Ticket']\n",
      " [list(['bad', 'solution']) 'Ticket']\n",
      " [list(['not', 'good', 'solution']) 'Ticket']\n",
      " [list(['no', 'help']) 'Ticket']\n",
      " [list(['wasted', 'my', 'time']) 'Ticket']\n",
      " [list(['useless', 'bot']) 'Ticket']\n",
      " [list(['create', 'a', 'ticket']) 'Ticket']]\n"
     ]
    }
   ],
   "source": [
    "print(\"Tags: {0}\".format(tags))\n",
    "print(\"------\")\n",
    "print(\"All Words: {0}\".format(all_words))\n",
    "print(\"------\")\n",
    "print(\"Tag-Token Mappings: {0}\".format(tag_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "oD4yUeZ7ABNl"
   },
   "outputs": [],
   "source": [
    "def build_bag(all_words, tokens): #BAg of Words\n",
    "    # reset our current bag\n",
    "    bag = []\n",
    "    for word in all_words:\n",
    "        # add 0/1 if the word is in our token\n",
    "        in_token = (word in tokens)\n",
    "        bag.append(1 * in_token)\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "psTRErOeABIa"
   },
   "outputs": [],
   "source": [
    "def build_training_set(tags, all_words, tag_tokens):\n",
    "    # define our variables to return\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "        \n",
    "    # iterate through each tag-token mapping\n",
    "    for tag_token in tag_tokens:\n",
    "        \n",
    "        # grab our needed values\n",
    "        tokens = tag_token[0]\n",
    "        tag = tag_token[1]\n",
    "        \n",
    "        # reset our current bag\n",
    "        current_bag = build_bag(all_words, tokens)\n",
    "            \n",
    "        # update our training inputs\n",
    "        train_x.append(current_bag)\n",
    "        \n",
    "        # set our outputs equal to 1 in the location\n",
    "        train_y.append(1 * (tags == tag))\n",
    "    \n",
    "    # return our values\n",
    "    return (np.array(train_x), np.array(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "lLcimbdoABF3"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = build_training_set(tags, all_words, tag_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGMwylA4ABDT",
    "outputId": "e33a99e4-4963-4dff-a2c3-4a02c4e2ea9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154, 183)\n",
      "(154, 8)\n",
      "Training Inputs: [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "-----\n",
      "Training Outputs: [[0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(\"Training Inputs: {0}\".format(train_x))\n",
    "print(\"-----\")\n",
    "print(\"Training Outputs: {0}\".format(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "vouh-EEdABAj"
   },
   "outputs": [],
   "source": [
    "# shuffled indexes, shuffiling to solve some bias\n",
    "shuffled_indexes = np.random.permutation(train_x.shape[0])\n",
    "# set new values for train_x and train_y\n",
    "train_x = train_x[shuffled_indexes]\n",
    "train_y = train_y[shuffled_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "wIK-U74PAA-L"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "fnMGyY44AA7n"
   },
   "outputs": [],
   "source": [
    "# declare our model\n",
    "model = Sequential()\n",
    "# add our layers\n",
    "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "5Asuc_7aAA46"
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qmKHAIZaAodH",
    "outputId": "f02c8712-d5f6-4341-9048-b3463078c40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "31/31 [==============================] - 3s 4ms/step - loss: 2.0762 - accuracy: 0.1429\n",
      "Epoch 2/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.9323 - accuracy: 0.2727\n",
      "Epoch 3/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 1.8340 - accuracy: 0.2857\n",
      "Epoch 4/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.7449 - accuracy: 0.3377\n",
      "Epoch 5/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.6236 - accuracy: 0.3701\n",
      "Epoch 6/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.5806 - accuracy: 0.4221\n",
      "Epoch 7/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.4623 - accuracy: 0.4156\n",
      "Epoch 8/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.2939 - accuracy: 0.5779\n",
      "Epoch 9/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.2227 - accuracy: 0.5455\n",
      "Epoch 10/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0622 - accuracy: 0.6299\n",
      "Epoch 11/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0526 - accuracy: 0.6104\n",
      "Epoch 12/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.9400 - accuracy: 0.6623\n",
      "Epoch 13/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.8620 - accuracy: 0.7143\n",
      "Epoch 14/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.7792\n",
      "Epoch 15/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.7034 - accuracy: 0.7662\n",
      "Epoch 16/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.8182\n",
      "Epoch 17/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.5658 - accuracy: 0.8442\n",
      "Epoch 18/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.3805 - accuracy: 0.9026\n",
      "Epoch 19/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8312\n",
      "Epoch 20/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8766\n",
      "Epoch 21/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8831\n",
      "Epoch 22/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.9351\n",
      "Epoch 23/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.9026\n",
      "Epoch 24/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.9156\n",
      "Epoch 25/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1657 - accuracy: 0.9740\n",
      "Epoch 26/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1996 - accuracy: 0.9481\n",
      "Epoch 27/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 0.9416\n",
      "Epoch 28/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2157 - accuracy: 0.9416\n",
      "Epoch 29/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1979 - accuracy: 0.9545\n",
      "Epoch 30/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1566 - accuracy: 0.9545\n",
      "Epoch 31/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 0.9740\n",
      "Epoch 32/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1760 - accuracy: 0.9675\n",
      "Epoch 33/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1241 - accuracy: 0.9675\n",
      "Epoch 34/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1166 - accuracy: 0.9805\n",
      "Epoch 35/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9740\n",
      "Epoch 36/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1087 - accuracy: 0.9675\n",
      "Epoch 37/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1403 - accuracy: 0.9610\n",
      "Epoch 38/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1365 - accuracy: 0.9740\n",
      "Epoch 39/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9870\n",
      "Epoch 40/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1098 - accuracy: 0.9740\n",
      "Epoch 41/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0729 - accuracy: 0.9870\n",
      "Epoch 42/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1064 - accuracy: 0.9675\n",
      "Epoch 43/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0587 - accuracy: 0.9805\n",
      "Epoch 44/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0837 - accuracy: 0.9805\n",
      "Epoch 45/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0898 - accuracy: 0.9675\n",
      "Epoch 46/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0931 - accuracy: 0.9740\n",
      "Epoch 47/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9870\n",
      "Epoch 48/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9870\n",
      "Epoch 50/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.9805\n",
      "Epoch 51/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0497 - accuracy: 0.9935\n",
      "Epoch 52/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.1009 - accuracy: 0.9545\n",
      "Epoch 53/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0856 - accuracy: 0.9740\n",
      "Epoch 54/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0758 - accuracy: 0.9740\n",
      "Epoch 55/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9935\n",
      "Epoch 57/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9935\n",
      "Epoch 58/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 1.0000\n",
      "Epoch 59/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9675\n",
      "Epoch 60/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0669 - accuracy: 0.9740\n",
      "Epoch 61/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0433 - accuracy: 0.9870\n",
      "Epoch 62/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.9740\n",
      "Epoch 63/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 1.0000\n",
      "Epoch 64/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9935\n",
      "Epoch 65/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9870\n",
      "Epoch 66/500\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9805\n",
      "Epoch 67/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9740\n",
      "Epoch 68/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9740\n",
      "Epoch 69/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9870\n",
      "Epoch 70/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9870\n",
      "Epoch 71/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9935\n",
      "Epoch 72/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 1.0000\n",
      "Epoch 73/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9870\n",
      "Epoch 74/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9870\n",
      "Epoch 75/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9870\n",
      "Epoch 76/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 0.9935\n",
      "Epoch 77/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9935\n",
      "Epoch 78/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9935\n",
      "Epoch 79/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 80/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9805\n",
      "Epoch 81/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9935\n",
      "Epoch 82/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9935\n",
      "Epoch 83/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9935\n",
      "Epoch 84/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0252 - accuracy: 0.9870\n",
      "Epoch 85/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0310 - accuracy: 0.9935\n",
      "Epoch 86/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9870\n",
      "Epoch 87/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 88/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 89/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9935\n",
      "Epoch 90/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 91/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 1.0000\n",
      "Epoch 92/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.9805\n",
      "Epoch 93/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 1.0000\n",
      "Epoch 94/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9935\n",
      "Epoch 95/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9870\n",
      "Epoch 96/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 97/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 98/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 99/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9870\n",
      "Epoch 100/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0450 - accuracy: 0.9935\n",
      "Epoch 101/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9935\n",
      "Epoch 102/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9935\n",
      "Epoch 103/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9935\n",
      "Epoch 104/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 105/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 106/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 107/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0354 - accuracy: 0.9935\n",
      "Epoch 108/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 1.0000\n",
      "Epoch 109/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9870\n",
      "Epoch 110/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 1.0000\n",
      "Epoch 111/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9870\n",
      "Epoch 112/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9870\n",
      "Epoch 113/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9935\n",
      "Epoch 114/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0523 - accuracy: 0.9935\n",
      "Epoch 116/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 0.9935\n",
      "Epoch 117/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9935\n",
      "Epoch 118/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 119/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9935\n",
      "Epoch 120/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9870\n",
      "Epoch 121/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0123 - accuracy: 0.9935\n",
      "Epoch 122/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9935\n",
      "Epoch 123/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9935\n",
      "Epoch 124/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 125/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 126/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 127/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 128/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9870\n",
      "Epoch 129/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0273 - accuracy: 0.9935\n",
      "Epoch 130/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9935\n",
      "Epoch 131/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 132/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9740\n",
      "Epoch 133/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9935\n",
      "Epoch 134/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 135/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 136/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 137/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0382 - accuracy: 0.9805\n",
      "Epoch 138/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 139/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 140/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 141/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 142/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 143/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9935\n",
      "Epoch 144/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9805\n",
      "Epoch 145/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9870\n",
      "Epoch 146/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9935\n",
      "Epoch 148/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9935\n",
      "Epoch 149/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9805\n",
      "Epoch 151/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9935\n",
      "Epoch 152/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0483 - accuracy: 0.9805\n",
      "Epoch 153/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9935\n",
      "Epoch 155/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9935\n",
      "Epoch 157/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0239 - accuracy: 0.9935\n",
      "Epoch 159/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9935\n",
      "Epoch 160/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9935\n",
      "Epoch 161/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0547 - accuracy: 0.9935\n",
      "Epoch 166/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 171/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9935\n",
      "Epoch 173/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9805\n",
      "Epoch 175/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9870\n",
      "Epoch 176/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9935\n",
      "Epoch 177/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9935\n",
      "Epoch 179/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9935\n",
      "Epoch 182/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0254 - accuracy: 0.9935\n",
      "Epoch 188/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0278 - accuracy: 0.9935\n",
      "Epoch 189/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9935\n",
      "Epoch 190/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9935\n",
      "Epoch 191/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9935\n",
      "Epoch 192/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9935\n",
      "Epoch 196/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9935\n",
      "Epoch 197/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9870\n",
      "Epoch 198/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0333 - accuracy: 0.9935\n",
      "Epoch 200/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9935\n",
      "Epoch 205/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9870\n",
      "Epoch 212/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0349 - accuracy: 0.9935\n",
      "Epoch 214/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9935\n",
      "Epoch 216/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9935\n",
      "Epoch 217/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9935\n",
      "Epoch 218/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9870\n",
      "Epoch 225/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0161 - accuracy: 0.9935\n",
      "Epoch 229/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9935\n",
      "Epoch 230/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9935\n",
      "Epoch 231/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9935\n",
      "Epoch 233/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9935\n",
      "Epoch 235/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0159 - accuracy: 0.9935\n",
      "Epoch 237/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0261 - accuracy: 0.9870\n",
      "Epoch 238/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 0.9935\n",
      "Epoch 239/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9935\n",
      "Epoch 241/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 0.9935\n",
      "Epoch 244/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9935\n",
      "Epoch 246/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0236 - accuracy: 0.9935\n",
      "Epoch 250/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9935\n",
      "Epoch 256/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 0.9935\n",
      "Epoch 258/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9935\n",
      "Epoch 261/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9935\n",
      "Epoch 262/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 268/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9935\n",
      "Epoch 269/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 0.9935\n",
      "Epoch 274/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9870\n",
      "Epoch 282/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9935\n",
      "Epoch 289/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9870\n",
      "Epoch 290/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9935\n",
      "Epoch 295/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9935\n",
      "Epoch 297/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9935\n",
      "Epoch 299/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9935\n",
      "Epoch 301/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9935\n",
      "Epoch 305/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9870\n",
      "Epoch 308/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 0.9935\n",
      "Epoch 317/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9935\n",
      "Epoch 318/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9935\n",
      "Epoch 323/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9935\n",
      "Epoch 324/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9935\n",
      "Epoch 331/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9935\n",
      "Epoch 332/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9935\n",
      "Epoch 349/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9935\n",
      "Epoch 357/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9935\n",
      "Epoch 358/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9935\n",
      "Epoch 362/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9935\n",
      "Epoch 366/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9935\n",
      "Epoch 367/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9935\n",
      "Epoch 374/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9935\n",
      "Epoch 380/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9935\n",
      "Epoch 387/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 0.9935\n",
      "Epoch 390/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.9510e-04 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9935\n",
      "Epoch 395/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 0.9935\n",
      "Epoch 410/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 5.3824e-04 - accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.5832e-04 - accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.1203e-04 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9870\n",
      "Epoch 419/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.1086e-04 - accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9935\n",
      "Epoch 429/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0075 - accuracy: 0.9935\n",
      "Epoch 431/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9935\n",
      "Epoch 435/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9935\n",
      "Epoch 438/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.7421e-04 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.3822e-04 - accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0336 - accuracy: 0.9870\n",
      "Epoch 450/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9935\n",
      "Epoch 453/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9935\n",
      "Epoch 454/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 0.9935\n",
      "Epoch 460/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.7401e-04 - accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.8837e-04 - accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0077 - accuracy: 0.9935\n",
      "Epoch 478/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9935\n",
      "Epoch 485/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 5.3232e-04 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.8611e-04 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 0.9935\n",
      "Epoch 498/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.2790e-04 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_x, train_y, epochs = 500, batch_size = 5, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "IWlSowTRAoac"
   },
   "outputs": [],
   "source": [
    "def predict_tag(user_input, model):\n",
    "    # tokenize/clean inputs\n",
    "    process_input = process_words(user_input)\n",
    "    \n",
    "    # build the bag\n",
    "    bag_input = build_bag(all_words, process_input)\n",
    "    bag_input = np.array([bag_input]) # note: convert to a numpy array\n",
    "    \n",
    "    # get our predicted values\n",
    "    pred_tag_values = model.predict(bag_input)\n",
    "    pred_tag_values = pred_tag_values[0] # note: flatten the 2-d array\n",
    "    \n",
    "    # get the index and value of the largest probability value\n",
    "    max_value_tag = np.argmax(pred_tag_values)\n",
    "    probability = np.max(pred_tag_values)\n",
    "    \n",
    "    # predict the tag and return\n",
    "    pred_tag = tags[max_value_tag]\n",
    "    return (pred_tag, probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2IypjhWAoX3",
    "outputId": "fe004c8a-e7d2-4578-f7b0-61c6b0f76082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Intro', 0.99999547)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the functionality\n",
    "# look at the probability for the bot's confidence level\n",
    "custom_input = \"How are you today?\"\n",
    "predict_tag(custom_input, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "dveao-erAoVJ"
   },
   "outputs": [],
   "source": [
    "def get_response(user_input, model, error_margin):\n",
    "    # get the predicted tag and probability\n",
    "    pred_tag, probability = predict_tag(user_input, model)\n",
    "    #print(pred_tag)\n",
    "    # get a list of different responses\n",
    "    responses = tag_responses[pred_tag] if probability > error_margin else tag_responses[\"noanswer\"]\n",
    "    #print(responses)\n",
    "    # check if we should exit the bot\n",
    "    should_exit_bot = (pred_tag == \"Exit\")\n",
    "    \n",
    "    # get the response\n",
    "    response = random.choice(responses)\n",
    "    \n",
    "    # return the variables\n",
    "    return (response, should_exit_bot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGP9TDxRAoSU",
    "outputId": "187c3b12-0d24-419d-f657-27cbd32fcc96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I hope I was able to assist you, Good Bye', True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the functionality,\n",
    "custom_input = \"Thank You\"\n",
    "get_response(custom_input, model, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "ccOWuZrHAoP_"
   },
   "outputs": [],
   "source": [
    "def chat():\n",
    "    # initialize variables\n",
    "    continue_chat = True\n",
    "    robot_prefix = \"Bot: \"\n",
    "    human_prefix = \"You: \"\n",
    "    \n",
    "    # give an introduction\n",
    "    print(robot_prefix + \"Hi! I am your Virtual Assistant for Great Learning. What are you looking for?\")\n",
    "    print(\"\")\n",
    "    \n",
    "    # continue while the user doesn't say goodbye\n",
    "    while (continue_chat):\n",
    "        # get the user input from the console\n",
    "        user_input = input(human_prefix)\n",
    "        \n",
    "        # get the response and exit condition from the helper function\n",
    "        response, should_exit = get_response(user_input, model, 0.75)\n",
    "        \n",
    "        # print the bot's response\n",
    "        print(robot_prefix + response)\n",
    "        print(\"\")\n",
    "        \n",
    "        # set the exit condition\n",
    "        continue_chat = not should_exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ssYNqdJAoNJ",
    "outputId": "9fb0dc0a-f5f0-4938-e881-ba7194b60b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hi! I am your Virtual Assistant for Great Learning. What are you looking for?\n",
      "\n",
      "You: how are you\n",
      "Bot: Hello! how can i help you ?\n",
      "\n",
      "You: olympus\n",
      "Bot: Link: Olympus wiki\n",
      "\n",
      "You: online\n",
      "Bot: Hello! how can i help you ?\n",
      "\n",
      "You: ML\n",
      "Bot: Link: Machine Learning wiki \n",
      "\n",
      "You: softmax\n",
      "Bot: Link: Neural Nets wiki\n",
      "\n",
      "You: what is your name\n",
      "Bot: I am your virtual learning assistant\n",
      "\n",
      "You: you are a joke\n",
      "Bot: Please use respectful words\n",
      "\n",
      "You: no help\n",
      "Bot: Tarnsferring the request to your PM\n",
      "\n",
      "You: quit\n",
      "Bot: I hope I was able to assist you, Good Bye\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "iHErtcuSXQfp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project -1: Statistical NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
